{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazonnews_dataframe = pd.DataFrame(json.load(open('./Data/investnewsamazon.json')))\n",
    "applenews_dataframe = pd.DataFrame(json.load(open('./Data/investnewsapple.json')))\n",
    "googlenews_dataframe = pd.DataFrame(json.load(open('./Data/investnewsgoogle.json')))\n",
    "metanews_dataframe = pd.DataFrame(json.load(open('./Data/investnewsmeta.json'))+json.load(open('./Data/investnewsmeta2.json')))\n",
    "msftnews_dataframe = pd.DataFrame(json.load(open('./Data/investnewsmsft.json')))\n",
    "nvidianews_dataframe = pd.DataFrame(json.load(open('./Data/investnewsnvidia.json')))\n",
    "samsungnews_dataframe = pd.DataFrame(json.load(open('./Data/investnewssamsung.json')))\n",
    "tencentnews_dataframe = pd.DataFrame(json.load(open('./Data/investnewstencent.json')))\n",
    "teslanews_dataframe = pd.DataFrame(json.load(open('./Data/investnewstesla.json'))+json.load(open('./Data/investnewstesla2.json')))\n",
    "tsmcnews_dataframe = pd.DataFrame(json.load(open('./Data/investnewstsmc.json')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_news_dataframes = [amazonnews_dataframe,\n",
    "                            applenews_dataframe,\n",
    "                            googlenews_dataframe,\n",
    "                            metanews_dataframe,\n",
    "                            msftnews_dataframe,\n",
    "                            nvidianews_dataframe,\n",
    "                            samsungnews_dataframe,\n",
    "                            tencentnews_dataframe,\n",
    "                            teslanews_dataframe,\n",
    "                            tsmcnews_dataframe\n",
    "                            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_news_sources = []\n",
    "\n",
    "for data in list_of_news_dataframes:\n",
    "    for source in list(data[\"Article Source\"].value_counts().index):\n",
    "        list_of_news_sources.append(source)\n",
    "\n",
    "list_of_news_sources = list(set(list_of_news_sources))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_news_sources = {'https://i-invdn-com.investing.com/news/providers/3e057c7f384e820886ff7ca52594bb7b.png':\"TipRanks\",\n",
    "                        'https://i-invdn-com.investing.com/news/providers/eafe6a3d95927d68b2173cda2ef9dc1c.png':\"StockNews\",\n",
    "                        'https://i-invdn-com.investing.com/news/providers/559698bc836be4174c42841b3c473303.png':\"Cointelegraph\",\n",
    "                        'https://i-invdn-com.investing.com/news/providers/05f392742320643916d28dbf568b3e6d.png':\"Coin_Edition\",\n",
    "                        'https://i-invdn-com.investing.com/news/providers/investing-new.png':\"Investing.com\",\n",
    "                        'https://i-invdn-com.investing.com/news/providers/Reuters.png':\"Reuters\",\n",
    "                        'https://i-invdn-com.investing.com/news/providers/bb01da8976e117e1320d62e0a2924827.png':\"DailyCoin\",\n",
    "                        'https://i-invdn-com.investing.com/logos/cryptovest.png':\"cryptovest\",\n",
    "                        'https://i-invdn-com.investing.com/news/providers/f669b6220c6f890e37e3e2eb71b9c82f.png':\"FXstreet\",\n",
    "                        'https://i-invdn-com.investing.com/news/providers/a3de4bfb9ab7d4545a5ee8ca37b74267.png':\"RealVision\",\n",
    "                        'https://i-invdn-com.investing.com/news/providers/05863679414a61354884428366cdf72d.jpg':\"U.Today\",\n",
    "                        'https://i-invdn-com.investing.com/logos/Bloomberg_new.png':\"Bloomberg\",\n",
    "                        'https://i-invdn-com.investing.com/news/providers/baa4350e859afe7cbe8cd35e7c6cc3d5.jpg':'BTC_Peers',\n",
    "                        'https://i-invdn-com.investing.com/logos/Business-Insider-small.png':'Business_Insider',\n",
    "                        'https://i-invdn-com.investing.com/news/providers/e28d7f12114c504773c172de3c698b61.png':\"MoneyShow\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessor (text_list):\n",
    "    if len(text_list) > 0:\n",
    "        if text_list[0][0] ==\"(\" and text_list[0][len(text_list[0])-1] == \")\":\n",
    "            text_list.pop(0)\n",
    "        if text_list[0][0:3] == \"By \" and len(text_list[0])<=100:\n",
    "            text_list.pop(0)\n",
    "    return text_list\n",
    "\n",
    "\n",
    "import string\n",
    "string.punctuation\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in '!\"#&\\'()*+/:;<=>?@[\\\\]^_`{|}~'])\n",
    "    \n",
    "    return punctuationfree\n",
    "#storing the punctuation free text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Pre-Processing\n",
    "def news_dataframe_preprocessing(dataframe):\n",
    "\n",
    "    dataframe.replace({\"Article Source\": dict_of_news_sources}, inplace = True)\n",
    "\n",
    "    dataframe['Date'] = dataframe['Date'].astype(str).str.extract('(\\w{3}\\s\\d{2},\\s\\d{4}\\s\\d{2}:\\d{2}\\w{2})').fillna('')\n",
    "\n",
    "    dataframe['Date'] = pd.to_datetime(dataframe['Date'])\n",
    "\n",
    "    print(f\"Original Dataframe Shape: {dataframe.shape}\")\n",
    "\n",
    "    dataframe.drop_duplicates(inplace=True,subset=['Date','Article Link'])\n",
    "\n",
    "    print(f\"Dataframe Shape after Removing Duplicates: {dataframe.shape}\")\n",
    "\n",
    "    dataframe = dataframe.loc[(dataframe['Date'] >= '2016-09-30')\n",
    "                            & (dataframe['Date'] <= '2022-09-30')].copy()\n",
    "\n",
    "    print(f\"Dataframe Shape after Date Filtering: {dataframe.shape}\")\n",
    "\n",
    "    dataframe['Text'] = dataframe['Text'].map(text_preprocessor)\n",
    "\n",
    "    dataframe['Text'] = [','.join(map(str, l)) for l in dataframe['Text']]\n",
    "\n",
    "    dataframe['Text'] = dataframe['Text'].replace(r'\\n',' ', regex=True) \n",
    "\n",
    "    dataframe[\"Cleaned_Text\"] = dataframe['Text'].replace(r'(^.{0,20}Investing.com.?\\–?)|(^.{0,20}Investing.?\\–?)|(^.{0,20}\\(Bloomberg.{0,20}\\)\\s\\-+)|(^.{0,130}\\(.{0,20}Reuters.{0,20}\\)\\s\\-{1,2})','', regex=True) \n",
    "\n",
    "    dataframe[\"Cleaned_Text\"] = dataframe[\"Cleaned_Text\"].replace(r'^.{0,5}Stocks\\sin\\sfocus(.{0,40}day:|.{0,60}Please\\srefresh\\sfor\\supdates)','', regex=True) \n",
    "\n",
    "    dataframe[\"Cleaned_Text\"] = dataframe[\"Cleaned_Text\"].replace(r'^.{0,5}Here.{0,100}(markets|market|radar)(\\w{2,15}\\.\\W|\\d{1,2}\\:)\\s?(Please\\srefresh\\sfor\\supdates\\.)?','', regex=True) \n",
    "\n",
    "    dataframe[\"Cleaned_Text\"] = dataframe[\"Cleaned_Text\"].replace(r'^Terms of Trade is a daily newsletter that untangles a world embroiled in trade wars.','', regex=True)\n",
    "\n",
    "    dataframe[\"Cleaned_Text\"] = dataframe[\"Cleaned_Text\"].replace(r'-',' ', regex=True)\n",
    "\n",
    "    dataframe[\"Cleaned_Text\"] = dataframe[\"Cleaned_Text\"].replace(r'\\bo\\b',' ', regex=True)    \n",
    "\n",
    "    dataframe[\"Cleaned_Text\"] = dataframe[\"Cleaned_Text\"].replace(r'\\W\\W+',' ', regex=True)\n",
    "\n",
    "    dataframe[\"Cleaned_Text\"] = dataframe[\"Cleaned_Text\"].replace(r'^.$','', regex=True)\n",
    "\n",
    "    dataframe[\"Cleaned_Text\"] = dataframe[\"Cleaned_Text\"].apply(lambda x:remove_punctuation(x))\n",
    "\n",
    "    dataframe[\"Cleaned_Text\"]= dataframe[\"Cleaned_Text\"].apply(lambda x: x.lower())\n",
    "\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe Shape: (13201, 6)\n",
      "Dataframe Shape after Removing Duplicates: (13201, 6)\n",
      "Dataframe Shape after Date Filtering: (12066, 6)\n",
      "Original Dataframe Shape: (14960, 6)\n",
      "Dataframe Shape after Removing Duplicates: (14960, 6)\n",
      "Dataframe Shape after Date Filtering: (12619, 6)\n",
      "Original Dataframe Shape: (12790, 6)\n",
      "Dataframe Shape after Removing Duplicates: (12790, 6)\n",
      "Dataframe Shape after Date Filtering: (10914, 6)\n",
      "Original Dataframe Shape: (16339, 6)\n",
      "Dataframe Shape after Removing Duplicates: (16331, 6)\n",
      "Dataframe Shape after Date Filtering: (14464, 6)\n",
      "Original Dataframe Shape: (7609, 6)\n",
      "Dataframe Shape after Removing Duplicates: (7609, 6)\n",
      "Dataframe Shape after Date Filtering: (6274, 6)\n",
      "Original Dataframe Shape: (1886, 6)\n",
      "Dataframe Shape after Removing Duplicates: (1886, 6)\n",
      "Dataframe Shape after Date Filtering: (1788, 6)\n",
      "Original Dataframe Shape: (2621, 6)\n",
      "Dataframe Shape after Removing Duplicates: (2621, 6)\n",
      "Dataframe Shape after Date Filtering: (2597, 6)\n",
      "Original Dataframe Shape: (635, 6)\n",
      "Dataframe Shape after Removing Duplicates: (635, 6)\n",
      "Dataframe Shape after Date Filtering: (540, 6)\n",
      "Original Dataframe Shape: (9485, 6)\n",
      "Dataframe Shape after Removing Duplicates: (9416, 6)\n",
      "Dataframe Shape after Date Filtering: (8645, 6)\n",
      "Original Dataframe Shape: (131, 6)\n",
      "Dataframe Shape after Removing Duplicates: (131, 6)\n",
      "Dataframe Shape after Date Filtering: (121, 6)\n"
     ]
    }
   ],
   "source": [
    "amazonnews_dataframe_cleaned = news_dataframe_preprocessing(amazonnews_dataframe)\n",
    "applenews_dataframe_cleaned = news_dataframe_preprocessing(applenews_dataframe)\n",
    "googlenews_dataframe_cleaned = news_dataframe_preprocessing(googlenews_dataframe)\n",
    "metanews_dataframe_cleaned = news_dataframe_preprocessing(metanews_dataframe)\n",
    "msftnews_dataframe_cleaned = news_dataframe_preprocessing(msftnews_dataframe)\n",
    "nvidianews_dataframe_cleaned = news_dataframe_preprocessing(nvidianews_dataframe)\n",
    "samsungnews_dataframe_cleaned = news_dataframe_preprocessing(samsungnews_dataframe)\n",
    "tencentnews_dataframe_cleaned = news_dataframe_preprocessing(tencentnews_dataframe)\n",
    "teslanews_dataframe_cleaned = news_dataframe_preprocessing(teslanews_dataframe)\n",
    "tsmcnews_dataframe_cleaned = news_dataframe_preprocessing(tsmcnews_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def sentiments(input):\n",
    "    if len(input)>2:\n",
    "        inputs = tokenizer(input, padding = True, truncation = True, return_tensors='pt')\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        return (predictions[0].tolist())\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "def getSubjectivity(text):\n",
    "   return TextBlob(text).sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Scores\n",
    "def news_dataframe_sentiment_transformation(dataframe):\n",
    "    dataframe[\"Title Sentiment\"] = dataframe[\"Title\"].apply(lambda x: sentiments(x))\n",
    "\n",
    "    dataframe[\"Title Positive\"] = dataframe[\"Title Sentiment\"].str[0].astype(float)\n",
    "    dataframe[\"Title Negative\"] = dataframe[\"Title Sentiment\"].str[1].astype(float)\n",
    "    dataframe[\"Title Neutral\"] = dataframe[\"Title Sentiment\"].str[2].astype(float)\n",
    "\n",
    "    dataframe[\"Text Sentiment\"] = dataframe[\"Cleaned_Text\"].apply(lambda x: sentiments(x))\n",
    "\n",
    "    dataframe[\"Text Positive\"] = dataframe[\"Text Sentiment\"].str[0].astype(float)\n",
    "    dataframe[\"Text Negative\"] = dataframe[\"Text Sentiment\"].str[1].astype(float)\n",
    "    dataframe[\"Text Neutral\"] = dataframe[\"Text Sentiment\"].str[2].astype(float)\n",
    "\n",
    "    dataframe.drop(['Title Sentiment', 'Text Sentiment'], axis=1, inplace = True)\n",
    "\n",
    "    dataframe[\"Title Subjectivity\"] = dataframe[\"Title\"].apply(getSubjectivity)\n",
    "    dataframe[\"Text Subjectivity\"] = dataframe[\"Cleaned_Text\"].apply(getSubjectivity)\n",
    "\n",
    "    return(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_news_dataframes_cleaned = [amazonnews_dataframe_cleaned,\n",
    "                                    applenews_dataframe_cleaned,\n",
    "                                    googlenews_dataframe_cleaned,\n",
    "                                    metanews_dataframe_cleaned,\n",
    "                                    msftnews_dataframe_cleaned,\n",
    "                                    nvidianews_dataframe_cleaned,\n",
    "                                    samsungnews_dataframe_cleaned,\n",
    "                                    tencentnews_dataframe_cleaned,\n",
    "                                    teslanews_dataframe_cleaned,\n",
    "                                    tsmcnews_dataframe_cleaned\n",
    "                            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dataframe Done:1\n",
      "Number of Dataframe Done:2\n",
      "Number of Dataframe Done:3\n",
      "Number of Dataframe Done:4\n",
      "Number of Dataframe Done:5\n",
      "Number of Dataframe Done:6\n",
      "Number of Dataframe Done:7\n",
      "Number of Dataframe Done:8\n",
      "Number of Dataframe Done:9\n",
      "Number of Dataframe Done:10\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for dataframe in list_of_news_dataframes_cleaned:\n",
    "    news_dataframe_sentiment_transformation(dataframe)\n",
    "    i += 1\n",
    "    print(f\"Number of Dataframe Done:{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "amazonnews_dataframe_cleaned.to_csv('amazonnews.csv', index=False)\n",
    "applenews_dataframe_cleaned.to_csv('applenews.csv', index=False)\n",
    "googlenews_dataframe_cleaned.to_csv('googlenews.csv', index=False)\n",
    "metanews_dataframe_cleaned.to_csv('metanews.csv', index=False)\n",
    "msftnews_dataframe_cleaned.to_csv('msftnews.csv', index=False)\n",
    "nvidianews_dataframe_cleaned.to_csv('nvidianews.csv', index=False)\n",
    "samsungnews_dataframe_cleaned.to_csv('samsungnews.csv', index=False)\n",
    "tencentnews_dataframe_cleaned.to_csv('tencentnews.csv', index=False)\n",
    "teslanews_dataframe_cleaned.to_csv('teslanews.csv', index=False)\n",
    "tsmcnews_dataframe_cleaned.to_csv('tsmcnews.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44425e06ba0c648dfd5bbfce51c25325d91aeaf103d5522f47a19ba32919c530"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
