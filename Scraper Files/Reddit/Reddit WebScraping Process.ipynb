{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Relevant Packages for Reddit WebScraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psaw in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: Click in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from psaw) (8.1.3)\n",
      "Requirement already satisfied: requests in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from psaw) (2.28.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\life is good\\appdata\\roaming\\python\\python310\\site-packages (from Click->psaw) (0.4.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->psaw) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->psaw) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->psaw) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->psaw) (2022.9.24)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip install psaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (7.6.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from praw) (1.4.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from praw) (2.3.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from prawcore<3,>=2.1->praw) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\life is good\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip install praw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psaw import PushshiftAPI\n",
    "import datetime as dt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from praw.models import MoreComments\n",
    "import sys, os\n",
    "import traceback\n",
    "import praw\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Please create a Reddit account, and enable developer mode to retrieve API token from https://www.reddit.com/prefs/apps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = \"Scrapper 1.0 by /u/Top_Transition3105\"\n",
    "reddit = praw.Reddit(\n",
    "    client_id='XXXXXXXXXXXXXXXXXXXX',\n",
    "    client_secret='XXXXXXXXXXXXXXXXXXXXXXXXXX',\n",
    "    user_agent = user_agent,\n",
    "    check_for_async=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PushshiftAPI allows us to obtain historical data from specified time range from Reddit\n",
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data scraped: 2\n",
      "Current Time = 10:31:03 \n",
      "\n",
      "2022-09-30 14:49:57+08:00\n",
      "Subreddit: stocks\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zx/x3_2llcj0tqd7f6y6p1wdbhr0000gn/T/ipykernel_88358/1484898555.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    181\u001b[0m                         \u001b[0mraw_comments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                         \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mtop_level_comment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_level_comment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMoreComments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/praw/models/reddit/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;34m\"\"\"Return the value of ``attribute``.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         raise AttributeError(\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/praw/models/reddit/submission.py\u001b[0m in \u001b[0;36m_fetch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0msubmission_listing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment_listing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mcomment_listing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mListing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reddit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomment_listing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/praw/models/reddit/submission.py\u001b[0m in \u001b[0;36m_fetch_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAPI_PATH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/praw/util/deprecate_args.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 )\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_old_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/praw/reddit.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[1;32m    945\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                 \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             )\n\u001b[1;32m    949\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBadRequest\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, path, data, files, json, params, timeout)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         )\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36m_request_with_retries\u001b[0;34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mretry_strategy_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         )\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, data, files, json, method, params, retry_strategy_state, timeout, url)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             )\n\u001b[1;32m    197\u001b[0m             log.debug(\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/prawcore/rate_limit.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, request_function, set_header_callback, *args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \"\"\"\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_header_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.7/site-packages/prawcore/rate_limit.py\u001b[0m in \u001b[0;36mdelay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Sleeping: {sleep_seconds:0.2f} seconds prior to call\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep_seconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_epoch=int(dt.datetime(2016, 1, 1).timestamp()) \n",
    "# year month day\n",
    "end_epoch=int(dt.datetime(2022, 10, 2).timestamp())\n",
    "\n",
    "title = set()\n",
    "\n",
    "posts_dict = {\"Subreddit\": [], 'Post URL': [] ,\"Date Created\": [], \"Title\": [], \"Self Text\": [],\n",
    "              \"Score\": [], \"Upvote Ratio\": [],\n",
    "              \"Total Comments\": [], \"Comments\": []}\n",
    "\n",
    "#For companies that are not so prevalent on Reddit, we expand our subreddit list to include more results\n",
    "#subreddit_list = ['stocks', 'investing', 'StockMarket', 'wallstreetbets', 'politics', 'Stock_Picks', 'finance']\n",
    "\n",
    "#For companies that are already prevalent on Reddit, we limit our scraping to the following subreddit\n",
    "subreddit_list = ['stocks', 'StockMarket', 'wallstreetbets']\n",
    "\n",
    "count = 0\n",
    "f = open('nvidiaNLPUpdated.txt', 'a')\n",
    "\n",
    "for subreddit_item in subreddit_list:\n",
    "\n",
    "    current_date = 0\n",
    "    date_count = 0\n",
    "    time_before_6 = 0\n",
    "    time_before_12 = 0\n",
    "    time_before_18 = 0\n",
    "    time_before_24 = 0\n",
    "    \n",
    "    for post in api.search_submissions(subreddit=subreddit_item, after = start_epoch, before=end_epoch):\n",
    "        try:\n",
    "            words_for_nvidia = ['nvidia', 'nvda', '$nvda']\n",
    "\n",
    "            title = post.title\n",
    "            try:\n",
    "                text = post.selftext\n",
    "            except Exception as e:\n",
    "                text = ''\n",
    "\n",
    "            for word in words_for_nvidia:\n",
    "                if (word.lower() in title.lower()) or (word.lower() in text.lower()):\n",
    "                    try:\n",
    "                        date_time = pd.to_datetime(post.created, unit = 's', utc=True).tz_convert('Asia/Singapore')\n",
    "                        date = date_time.date()\n",
    "                        hour = date_time.hour\n",
    "                        # print(date_time.hour)\n",
    "\n",
    "                        if hour <=6:\n",
    "                            time_before_6 += 1\n",
    "                        elif hour > 6 and hour <=12:\n",
    "                            time_before_12 += 1\n",
    "                        elif hour > 12 and hour <=18:\n",
    "                            time_before_18 += 1\n",
    "                        elif hour > 18 and hour <24:\n",
    "                            time_before_24\n",
    "\n",
    "                        if current_date == date:\n",
    "                            if date_count > 4:\n",
    "                                continue\n",
    "                        if date != current_date:\n",
    "                            date_count = 0\n",
    "                            current_date = date\n",
    "                            time_before_6 = 0\n",
    "                            time_before_12 = 0\n",
    "                            time_before_18 = 0\n",
    "                            time_before_24 = 0\n",
    "\n",
    "                        if time_before_6 > 1 and hour <=6:\n",
    "                            continue\n",
    "                        elif time_before_12 > 1 and hour > 6 and hour <=12:\n",
    "                            continue\n",
    "                        elif time_before_18 > 1 and hour > 12 and hour <=18:\n",
    "                            continue\n",
    "                        elif time_before_24 > 1 and hour > 18 and hour <24:\n",
    "                            continue\n",
    "\n",
    "                        date_count += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(traceback.format_exc())\n",
    "                        pass  \n",
    "\n",
    "                    posts_dict[\"Subreddit\"].append(subreddit_item)\n",
    "\n",
    "                    try:\n",
    "                        # URL of each post\n",
    "                        url = post.url\n",
    "                        posts_dict[\"Post URL\"].append(post.url)\n",
    "                    except Exception as e:\n",
    "                        url = None\n",
    "                        posts_dict[\"Post URL\"].append(None)\n",
    "                        print(traceback.format_exc())\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        # Date of each post\n",
    "                        date_time = pd.to_datetime(post.created, unit = 's', utc=True).tz_convert('Asia/Singapore')\n",
    "                        print(date_time)\n",
    "                        print(f\"Subreddit: {subreddit_item}\")\n",
    "                        posts_dict[\"Date Created\"].append(date_time)\n",
    "                    except Exception as e:\n",
    "                        date_time = None\n",
    "                        posts_dict[\"Date Created\"].append(None)\n",
    "                        print(traceback.format_exc())\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        # Title of each post\n",
    "                        # Checking if title contains meta\n",
    "                        posts_dict[\"Title\"].append(title)\n",
    "                    except Exception as e:\n",
    "                        posts_dict[\"Title\"].append(None)\n",
    "                        print(traceback.format_exc())\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        # Content of each post\n",
    "                        content = post.selftext\n",
    "                        posts_dict[\"Self Text\"].append(content)\n",
    "                    except Exception as e:\n",
    "                        posts_dict[\"Self Text\"].append(None)\n",
    "                        print(traceback.format_exc())\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        # Score of each post\n",
    "                        score = post.score\n",
    "                        posts_dict[\"Score\"].append(score)\n",
    "                    except Exception as e:\n",
    "                        posts_dict[\"Score\"].append(None)\n",
    "                        print(traceback.format_exc())\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        # Upvote Ratio of each post\n",
    "                        upvote = post.upvote_ratio\n",
    "                        posts_dict[\"Upvote Ratio\"].append(upvote)\n",
    "                    except Exception as e:\n",
    "                        posts_dict[\"Upvote Ratio\"].append(None)\n",
    "                        print(traceback.format_exc())\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        # Num comments of each post\n",
    "                        comments_no = post.num_comments\n",
    "                        posts_dict[\"Total Comments\"].append(comments_no)\n",
    "                    except Exception as e:\n",
    "                        posts_dict[\"Total Comments\"].append(None)\n",
    "                        print(traceback.format_exc())\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        #Extracting comments using reddit.submission(\"id\") instead\n",
    "                        # print(post.url)\n",
    "                        raw_comments = []\n",
    "                        submission = reddit.submission(post.id)\n",
    "                        for top_level_comment in submission.comments:\n",
    "                            if isinstance(top_level_comment, MoreComments):\n",
    "                                continue\n",
    "                            raw_comments.append(top_level_comment.body)\n",
    "                        raw_comments = raw_comments[1:]\n",
    "                        posts_dict[\"Comments\"].append(raw_comments)\n",
    "                    except Exception as e:\n",
    "                        posts_dict[\"Comments\"].append(None)\n",
    "                        print(traceback.format_exc())\n",
    "                        pass\n",
    "                    #clear_output for memory purposes else jupyter notebook might crash from excessive printing\n",
    "                    clear_output(wait=True)\n",
    "                    count += 1\n",
    "                    print(f\"Number of data scraped: {count}\")\n",
    "                    now = dt.datetime.now()\n",
    "                    current_time = now.strftime(\"%H:%M:%S\")\n",
    "                    print(\"Current Time =\", current_time, \"\\n\")\n",
    "                    \n",
    "                    conversion_dict = {'Post URL': url,\"Date Created\": [date_time], \"Title\": [title], \"Self Text\": [content],\n",
    "                                       \"Score\": [score], \"Upvote Ratio\": [upvote], \"Total Comments\": [comments_no], \"Comments\": [raw_comments]}\n",
    "\n",
    "                    conversion_dict = pd.DataFrame(conversion_dict)\n",
    "                    output = conversion_dict.to_json(orient= 'index')\n",
    "            \n",
    "                    f.write(output)  # python will convert \\n to os.linesep\n",
    "                    f.write(\"\\n\")\n",
    "                    \n",
    "                    break\n",
    "        except ConnectionError as e:\n",
    "            print(str(e))\n",
    "            print(\"********Portal New connection timed out***********\")\n",
    "            print(\"********Sleeping***********\")\n",
    "            time.sleep(30)\n",
    "            print(\"********Resume***********\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: The above cell would work perfectly, please ignore the KeyboardInterrupt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_result = pd.DataFrame(posts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia_NLP = reddit_result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia_NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = nvidia_NLP.to_json(orient= 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nvidia_NLP.txt', 'w') as f:\n",
    "    f.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia_NLP.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a08c092cedc1da88a066329bd18d2b39dc63974f08304c21d718ec4521f50ed1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
